{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fdf2a28a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\kanta\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.32.5)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\kanta\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (1.1.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\kanta\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.3.3)\n",
      "Requirement already satisfied: openai in c:\\users\\kanta\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (1.82.1)\n",
      "Requirement already satisfied: py2neo in c:\\users\\kanta\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2021.2.4)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\kanta\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\kanta\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\kanta\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\kanta\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests) (2025.4.26)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\kanta\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2.3.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\kanta\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\kanta\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\kanta\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\kanta\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from openai) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\kanta\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\kanta\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\kanta\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from openai) (0.10.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\kanta\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from openai) (2.11.5)\n",
      "Requirement already satisfied: sniffio in c:\\users\\kanta\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\kanta\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\kanta\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from openai) (4.13.2)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\kanta\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\kanta\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\kanta\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\kanta\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\kanta\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n",
      "Requirement already satisfied: interchange~=2021.0.4 in c:\\users\\kanta\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from py2neo) (2021.0.4)\n",
      "Requirement already satisfied: monotonic in c:\\users\\kanta\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from py2neo) (1.6)\n",
      "Requirement already satisfied: packaging in c:\\users\\kanta\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from py2neo) (25.0)\n",
      "Requirement already satisfied: pansi>=2020.7.3 in c:\\users\\kanta\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from py2neo) (2024.11.0)\n",
      "Requirement already satisfied: pygments>=2.0.0 in c:\\users\\kanta\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from py2neo) (2.19.2)\n",
      "Requirement already satisfied: six>=1.15.0 in c:\\users\\kanta\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from py2neo) (1.17.0)\n",
      "Requirement already satisfied: pillow in c:\\users\\kanta\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pansi>=2020.7.3->py2neo) (11.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\kanta\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# Cell 0 – Install required libraries (run once)\n",
    "\n",
    "%pip install requests python-dotenv pandas openai py2neo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "922bf5cc",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15058b6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NewsAPI key loaded: True\n",
      "OpenAI key loaded: True\n",
      "Neo4j URI: bolt://localhost:7687\n"
     ]
    }
   ],
   "source": [
    "# Cell 1 – Imports & load environment variables\n",
    "\n",
    "import os\n",
    "import json\n",
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from py2neo import Graph, Node, Relationship\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "# Load keys from .env\n",
    "load_dotenv()\n",
    "\n",
    "NEWSAPI_KEY = os.getenv(\"NEWSAPI_KEY\")\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "NEO4J_URI = os.getenv(\"NEO4J_URI\")\n",
    "NEO4J_USER = os.getenv(\"NEO4J_USER\")\n",
    "NEO4J_PASSWORD = os.getenv(\"NEO4J_PASSWORD\")\n",
    "\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "print(\"NewsAPI key loaded:\", NEWSAPI_KEY is not None)\n",
    "print(\"OpenAI key loaded:\", OPENAI_API_KEY is not None)\n",
    "print(\"Neo4j URI:\", NEO4J_URI)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302c8c5a",
   "metadata": {},
   "source": [
    "### Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0143b86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kanta\\AppData\\Local\\Temp\\ipykernel_40304\\1138030152.py:5: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  from_date = (datetime.utcnow() - timedelta(days=days_back)).strftime(\"%Y-%m-%d\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>source</th>\n",
       "      <th>author</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>content</th>\n",
       "      <th>url</th>\n",
       "      <th>published_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Yahoo Entertainment</td>\n",
       "      <td>By Brad Haynes</td>\n",
       "      <td>Exclusive-Google deal for Amazon reforestation...</td>\n",
       "      <td>BELEM, Brazil (Reuters) -Google has struck its...</td>\n",
       "      <td>By Brad Haynes\\r\\nBELEM, Brazil (Reuters) -Goo...</td>\n",
       "      <td>https://finance.yahoo.com/news/exclusive-googl...</td>\n",
       "      <td>2025-11-06T10:01:59Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Gizmodo.com</td>\n",
       "      <td>Rhett Jones</td>\n",
       "      <td>$120 Million Exploit Has Chilling Effect on En...</td>\n",
       "      <td>The incident casts a dark shadow on the trustw...</td>\n",
       "      <td>Balancer, which is a decentralized finance (De...</td>\n",
       "      <td>https://gizmodo.com/120-million-exploit-has-ch...</td>\n",
       "      <td>2025-11-03T20:00:33Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>The Verge</td>\n",
       "      <td>Nilay Patel</td>\n",
       "      <td>Lyft CEO David Risher on paying drivers more a...</td>\n",
       "      <td>Today, I’m talking with David Risher, who is t...</td>\n",
       "      <td>&lt;ul&gt;&lt;li&gt;&lt;/li&gt;&lt;li&gt;&lt;/li&gt;&lt;li&gt;&lt;/li&gt;&lt;/ul&gt;\\r\\nRisher...</td>\n",
       "      <td>https://www.theverge.com/podcast/811532/lyft-u...</td>\n",
       "      <td>2025-11-03T15:02:30Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>BBC News</td>\n",
       "      <td>None</td>\n",
       "      <td>COP30: World leaders take aim at Trump for cli...</td>\n",
       "      <td>World leaders address COP30 climate summit in ...</td>\n",
       "      <td>Esme Stallard,Climate and science reporter, BB...</td>\n",
       "      <td>https://www.bbc.com/news/articles/cn4j8dgnj1wo</td>\n",
       "      <td>2025-11-06T18:49:14Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>New Scientist</td>\n",
       "      <td>Luke Taylor</td>\n",
       "      <td>COP30: Can Brazil summit get climate negotiati...</td>\n",
       "      <td>Expectations are low for the UN climate confer...</td>\n",
       "      <td>A preparatory ministerial meeting in Brasilia,...</td>\n",
       "      <td>https://www.newscientist.com/article/2502430-c...</td>\n",
       "      <td>2025-11-04T14:00:40Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id               source          author  \\\n",
       "0   0  Yahoo Entertainment  By Brad Haynes   \n",
       "1   1          Gizmodo.com     Rhett Jones   \n",
       "2   2            The Verge     Nilay Patel   \n",
       "3   3             BBC News            None   \n",
       "4   4        New Scientist     Luke Taylor   \n",
       "\n",
       "                                               title  \\\n",
       "0  Exclusive-Google deal for Amazon reforestation...   \n",
       "1  $120 Million Exploit Has Chilling Effect on En...   \n",
       "2  Lyft CEO David Risher on paying drivers more a...   \n",
       "3  COP30: World leaders take aim at Trump for cli...   \n",
       "4  COP30: Can Brazil summit get climate negotiati...   \n",
       "\n",
       "                                         description  \\\n",
       "0  BELEM, Brazil (Reuters) -Google has struck its...   \n",
       "1  The incident casts a dark shadow on the trustw...   \n",
       "2  Today, I’m talking with David Risher, who is t...   \n",
       "3  World leaders address COP30 climate summit in ...   \n",
       "4  Expectations are low for the UN climate confer...   \n",
       "\n",
       "                                             content  \\\n",
       "0  By Brad Haynes\\r\\nBELEM, Brazil (Reuters) -Goo...   \n",
       "1  Balancer, which is a decentralized finance (De...   \n",
       "2  <ul><li></li><li></li><li></li></ul>\\r\\nRisher...   \n",
       "3  Esme Stallard,Climate and science reporter, BB...   \n",
       "4  A preparatory ministerial meeting in Brasilia,...   \n",
       "\n",
       "                                                 url          published_at  \n",
       "0  https://finance.yahoo.com/news/exclusive-googl...  2025-11-06T10:01:59Z  \n",
       "1  https://gizmodo.com/120-million-exploit-has-ch...  2025-11-03T20:00:33Z  \n",
       "2  https://www.theverge.com/podcast/811532/lyft-u...  2025-11-03T15:02:30Z  \n",
       "3     https://www.bbc.com/news/articles/cn4j8dgnj1wo  2025-11-06T18:49:14Z  \n",
       "4  https://www.newscientist.com/article/2502430-c...  2025-11-04T14:00:40Z  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 2 – Fetch financial news using NewsAPI\n",
    "\n",
    "def fetch_financial_news(query=\"Amazon stock\", page_size=20, days_back=3):\n",
    "    base_url = \"https://newsapi.org/v2/everything\"\n",
    "    from_date = (datetime.utcnow() - timedelta(days=days_back)).strftime(\"%Y-%m-%d\")\n",
    "    \n",
    "    params = {\n",
    "        \"q\": query,\n",
    "        \"language\": \"en\",\n",
    "        \"from\": from_date,\n",
    "        \"sortBy\": \"relevancy\",\n",
    "        \"pageSize\": page_size,\n",
    "        \"apiKey\": NEWSAPI_KEY,\n",
    "    }\n",
    "    \n",
    "    resp = requests.get(base_url, params=params)\n",
    "    data = resp.json()\n",
    "    \n",
    "    if data.get(\"status\") != \"ok\":\n",
    "        print(\"Error:\", data)\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    articles = data.get(\"articles\", [])\n",
    "    rows = []\n",
    "    for i, art in enumerate(articles):\n",
    "        rows.append({\n",
    "            \"id\": i,\n",
    "            \"source\": art[\"source\"][\"name\"],\n",
    "            \"author\": art.get(\"author\"),\n",
    "            \"title\": art.get(\"title\"),\n",
    "            \"description\": art.get(\"description\"),\n",
    "            \"content\": art.get(\"content\"),\n",
    "            \"url\": art.get(\"url\"),\n",
    "            \"published_at\": art.get(\"publishedAt\"),\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "df_news = fetch_financial_news(query=\"Amazon finance\", page_size=15, days_back=7)\n",
    "df_news.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "751aef58",
   "metadata": {},
   "source": [
    "### Text cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b40ee23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of articles: 15\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>source</th>\n",
       "      <th>title</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Yahoo Entertainment</td>\n",
       "      <td>Exclusive-Google deal for Amazon reforestation...</td>\n",
       "      <td>Exclusive-Google deal for Amazon reforestation...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Gizmodo.com</td>\n",
       "      <td>$120 Million Exploit Has Chilling Effect on En...</td>\n",
       "      <td>$120 Million Exploit Has Chilling Effect on En...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>The Verge</td>\n",
       "      <td>Lyft CEO David Risher on paying drivers more a...</td>\n",
       "      <td>Lyft CEO David Risher on paying drivers more a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>BBC News</td>\n",
       "      <td>COP30: World leaders take aim at Trump for cli...</td>\n",
       "      <td>COP30: World leaders take aim at Trump for cli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>New Scientist</td>\n",
       "      <td>COP30: Can Brazil summit get climate negotiati...</td>\n",
       "      <td>COP30: Can Brazil summit get climate negotiati...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id               source                                              title  \\\n",
       "0   0  Yahoo Entertainment  Exclusive-Google deal for Amazon reforestation...   \n",
       "1   1          Gizmodo.com  $120 Million Exploit Has Chilling Effect on En...   \n",
       "2   2            The Verge  Lyft CEO David Risher on paying drivers more a...   \n",
       "3   3             BBC News  COP30: World leaders take aim at Trump for cli...   \n",
       "4   4        New Scientist  COP30: Can Brazil summit get climate negotiati...   \n",
       "\n",
       "                                          clean_text  \n",
       "0  Exclusive-Google deal for Amazon reforestation...  \n",
       "1  $120 Million Exploit Has Chilling Effect on En...  \n",
       "2  Lyft CEO David Risher on paying drivers more a...  \n",
       "3  COP30: World leaders take aim at Trump for cli...  \n",
       "4  COP30: Can Brazil summit get climate negotiati...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 3 – Basic preprocessing: combine text and clean\n",
    "\n",
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    if text is None:\n",
    "        return \"\"\n",
    "    text = re.sub(r\"\\s+\", \" \", text)      # collapse whitespace\n",
    "    text = text.replace(\"…\", \"...\")\n",
    "    return text.strip()\n",
    "\n",
    "df_news[\"raw_text\"] = (\n",
    "    df_news[\"title\"].fillna(\"\") + \". \" +\n",
    "    df_news[\"description\"].fillna(\"\") + \". \" +\n",
    "    df_news[\"content\"].fillna(\"\")\n",
    ")\n",
    "\n",
    "df_news[\"clean_text\"] = df_news[\"raw_text\"].apply(clean_text)\n",
    "\n",
    "print(\"Number of articles:\", len(df_news))\n",
    "df_news[[\"id\", \"source\", \"title\", \"clean_text\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9eb193",
   "metadata": {},
   "source": [
    "### Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65e6da9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4 – LLM helper to extract entities and relationships\n",
    "\n",
    "SYSTEM_PROMPT = \"\"\"\n",
    "You are an information extraction assistant specialized in financial news.\n",
    "Given a piece of text, extract key entities and relationships as triplets.\n",
    "\n",
    "Only output valid JSON with the following format:\n",
    "[\n",
    "  {\n",
    "    \"head\": \"Amazon\",\n",
    "    \"head_type\": \"Company\",\n",
    "    \"relation\": \"acquires\",\n",
    "    \"tail\": \"Whole Foods\",\n",
    "    \"tail_type\": \"Company\",\n",
    "    \"evidence\": \"short quote from the text\"\n",
    "  },\n",
    "  ...\n",
    "]\n",
    "\n",
    "Entity types can include: Company, Person, Product, Market, Index, Currency, Metric, Date, Event, Other.\n",
    "Relation examples: acquires, invests_in, partners_with, sues, fined_by, appoints, reports_result, impacts, located_in, etc.\n",
    "\"\"\"\n",
    "\n",
    "def extract_triples_llm(text, max_chars=2000):\n",
    "    # optionally truncate long text\n",
    "    text = text[:max_chars]\n",
    "    \n",
    "    user_prompt = f\"\"\"\n",
    "Extract financial knowledge graph triplets from the following news text.\n",
    "\n",
    "Text:\n",
    "\\\"\\\"\\\"{text}\\\"\\\"\\\"\n",
    "\n",
    "Remember: only output a JSON array of objects with keys\n",
    "[head, head_type, relation, tail, tail_type, evidence].\n",
    "\"\"\"\n",
    "\n",
    "    resp = client.responses.create(\n",
    "        model=\"gpt-4.1\",  # or another model you have\n",
    "        input=[\n",
    "            {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "            {\"role\": \"user\", \"content\": user_prompt}\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    content = resp.output[0].content[0].text\n",
    "    # Try to parse JSON\n",
    "    try:\n",
    "        triples = json.loads(content)\n",
    "    except json.JSONDecodeError:\n",
    "        print(\"JSON parse error, raw content:\\n\", content)\n",
    "        triples = []\n",
    "    return triples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f0e12e4",
   "metadata": {},
   "source": [
    "### Run extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4fcf3555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Extracting from article 0: Exclusive-Google deal for Amazon reforestation makes Brazilian startup its top carbon credit supplier ===\n",
      "\n",
      "=== Extracting from article 1: $120 Million Exploit Has Chilling Effect on Entire Crypto Ecosystem ===\n",
      "\n",
      "=== Extracting from article 2: Lyft CEO David Risher on paying drivers more and the shift to robotaxis ===\n",
      "\n",
      "=== Extracting from article 3: COP30: World leaders take aim at Trump for climate inaction ===\n",
      "\n",
      "=== Extracting from article 4: COP30: Can Brazil summit get climate negotiations back on track? ===\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(17,\n",
       " [{'head': 'Google',\n",
       "   'head_type': 'Company',\n",
       "   'relation': 'finance',\n",
       "   'tail': 'restoration of the Amazon rainforest',\n",
       "   'tail_type': 'Event',\n",
       "   'evidence': 'Google has struck its biggest carbon removal deal, agreeing to finance restoration of the Amazon rainforest',\n",
       "   'article_id': 0,\n",
       "   'source': 'Yahoo Entertainment',\n",
       "   'published_at': '2025-11-06T10:01:59Z'},\n",
       "  {'head': 'Google',\n",
       "   'head_type': 'Company',\n",
       "   'relation': 'partners_with',\n",
       "   'tail': 'Mombak',\n",
       "   'tail_type': 'Company',\n",
       "   'evidence': 'Google has struck its biggest carbon removal deal, agreeing to finance restoration of the Amazon rainforest with Brazilian startup Mombak',\n",
       "   'article_id': 0,\n",
       "   'source': 'Yahoo Entertainment',\n",
       "   'published_at': '2025-11-06T10:01:59Z'},\n",
       "  {'head': 'Mombak',\n",
       "   'head_type': 'Company',\n",
       "   'relation': 'supplies',\n",
       "   'tail': 'carbon credits',\n",
       "   'tail_type': 'Product',\n",
       "   'evidence': 'Brazilian startup its top carbon credit supplier',\n",
       "   'article_id': 0,\n",
       "   'source': 'Yahoo Entertainment',\n",
       "   'published_at': '2025-11-06T10:01:59Z'}])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 5 – Run LLM extraction on first N articles\n",
    "\n",
    "N = min(5, len(df_news))   # change as you like\n",
    "all_triples = []\n",
    "\n",
    "for _, row in df_news.head(N).iterrows():\n",
    "    article_id = row[\"id\"]\n",
    "    text = row[\"clean_text\"]\n",
    "    print(f\"\\n=== Extracting from article {article_id}: {row['title']} ===\")\n",
    "    \n",
    "    triples = extract_triples_llm(text)\n",
    "    for t in triples:\n",
    "        t[\"article_id\"] = int(article_id)\n",
    "        t[\"source\"] = row[\"source\"]\n",
    "        t[\"published_at\"] = row[\"published_at\"]\n",
    "        all_triples.append(t)\n",
    "\n",
    "len(all_triples), all_triples[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4877fdf5",
   "metadata": {},
   "source": [
    "### Data cleaning and Triplet Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f59f68b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned triples: 17\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>head</th>\n",
       "      <th>head_type</th>\n",
       "      <th>relation</th>\n",
       "      <th>tail</th>\n",
       "      <th>tail_type</th>\n",
       "      <th>evidence</th>\n",
       "      <th>article_id</th>\n",
       "      <th>source</th>\n",
       "      <th>published_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Google</td>\n",
       "      <td>Company</td>\n",
       "      <td>finance</td>\n",
       "      <td>restoration of the Amazon rainforest</td>\n",
       "      <td>Event</td>\n",
       "      <td>Google has struck its biggest carbon removal d...</td>\n",
       "      <td>0</td>\n",
       "      <td>Yahoo Entertainment</td>\n",
       "      <td>2025-11-06T10:01:59Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Google</td>\n",
       "      <td>Company</td>\n",
       "      <td>partners_with</td>\n",
       "      <td>Mombak</td>\n",
       "      <td>Company</td>\n",
       "      <td>Google has struck its biggest carbon removal d...</td>\n",
       "      <td>0</td>\n",
       "      <td>Yahoo Entertainment</td>\n",
       "      <td>2025-11-06T10:01:59Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mombak</td>\n",
       "      <td>Company</td>\n",
       "      <td>supplies</td>\n",
       "      <td>carbon credits</td>\n",
       "      <td>Product</td>\n",
       "      <td>Brazilian startup its top carbon credit supplier</td>\n",
       "      <td>0</td>\n",
       "      <td>Yahoo Entertainment</td>\n",
       "      <td>2025-11-06T10:01:59Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Balancer</td>\n",
       "      <td>Company</td>\n",
       "      <td>exploited_in</td>\n",
       "      <td>$120 Million Exploit</td>\n",
       "      <td>Event</td>\n",
       "      <td>Balancer, which is a decentralized finance (De...</td>\n",
       "      <td>1</td>\n",
       "      <td>Gizmodo.com</td>\n",
       "      <td>2025-11-03T20:00:33Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>$120 Million Exploit</td>\n",
       "      <td>Event</td>\n",
       "      <td>impacts</td>\n",
       "      <td>crypto ecosystem</td>\n",
       "      <td>Market</td>\n",
       "      <td>$120 Million Exploit Has Chilling Effect on En...</td>\n",
       "      <td>1</td>\n",
       "      <td>Gizmodo.com</td>\n",
       "      <td>2025-11-03T20:00:33Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   head head_type       relation  \\\n",
       "0                Google   Company        finance   \n",
       "1                Google   Company  partners_with   \n",
       "2                Mombak   Company       supplies   \n",
       "3              Balancer   Company   exploited_in   \n",
       "4  $120 Million Exploit     Event        impacts   \n",
       "\n",
       "                                   tail tail_type  \\\n",
       "0  restoration of the Amazon rainforest     Event   \n",
       "1                                Mombak   Company   \n",
       "2                        carbon credits   Product   \n",
       "3                  $120 Million Exploit     Event   \n",
       "4                      crypto ecosystem    Market   \n",
       "\n",
       "                                            evidence  article_id  \\\n",
       "0  Google has struck its biggest carbon removal d...           0   \n",
       "1  Google has struck its biggest carbon removal d...           0   \n",
       "2   Brazilian startup its top carbon credit supplier           0   \n",
       "3  Balancer, which is a decentralized finance (De...           1   \n",
       "4  $120 Million Exploit Has Chilling Effect on En...           1   \n",
       "\n",
       "                source          published_at  \n",
       "0  Yahoo Entertainment  2025-11-06T10:01:59Z  \n",
       "1  Yahoo Entertainment  2025-11-06T10:01:59Z  \n",
       "2  Yahoo Entertainment  2025-11-06T10:01:59Z  \n",
       "3          Gizmodo.com  2025-11-03T20:00:33Z  \n",
       "4          Gizmodo.com  2025-11-03T20:00:33Z  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 6 – Clean and standardize triplets\n",
    "\n",
    "triples_df = pd.DataFrame(all_triples)\n",
    "\n",
    "def normalize_name(x):\n",
    "    if not isinstance(x, str):\n",
    "        return \"\"\n",
    "    x = x.strip()\n",
    "    # simple normalization – you can add more\n",
    "    return x\n",
    "\n",
    "for col in [\"head\", \"tail\", \"relation\", \"head_type\", \"tail_type\"]:\n",
    "    triples_df[col] = triples_df[col].astype(str).apply(normalize_name)\n",
    "\n",
    "# Remove empty head or tail\n",
    "triples_df = triples_df[(triples_df[\"head\"] != \"\") & (triples_df[\"tail\"] != \"\")]\n",
    "\n",
    "# Drop duplicates\n",
    "triples_df = triples_df.drop_duplicates(\n",
    "    subset=[\"head\", \"relation\", \"tail\", \"article_id\"]\n",
    ").reset_index(drop=True)\n",
    "\n",
    "print(\"Cleaned triples:\", len(triples_df))\n",
    "triples_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ee3489",
   "metadata": {},
   "source": [
    "### Connect to Neo4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f01dd1d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><th>msg</th></tr><tr><td style=\"text-align:left\">Neo4j connection OK</td></tr></table>"
      ],
      "text/plain": [
       " msg                 \n",
       "---------------------\n",
       " Neo4j connection OK "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 7 – Connect to Neo4j\n",
    "\n",
    "graph = Graph(NEO4J_URI, auth=(NEO4J_USER, NEO4J_PASSWORD))\n",
    "\n",
    "# Optional: test query\n",
    "graph.run(\"RETURN 'Neo4j connection OK' AS msg\").to_table()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7466cb1f",
   "metadata": {},
   "source": [
    "### Graph construct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6e6fb055",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserted into Neo4j!\n"
     ]
    }
   ],
   "source": [
    "# Cell 8 – Create nodes and relationships in Neo4j\n",
    "\n",
    "def upsert_triplet_to_neo4j(row):\n",
    "    head_name = row[\"head\"]\n",
    "    tail_name = row[\"tail\"]\n",
    "    rel = row[\"relation\"]\n",
    "    head_type = row.get(\"head_type\", \"Entity\")\n",
    "    tail_type = row.get(\"tail_type\", \"Entity\")\n",
    "    evidence = row.get(\"evidence\", \"\")\n",
    "    source = row.get(\"source\", \"\")\n",
    "    published_at = row.get(\"published_at\", \"\")\n",
    "    \n",
    "    cypher = \"\"\"\n",
    "    MERGE (h:Entity {name: $head_name})\n",
    "      ON CREATE SET h.type = $head_type\n",
    "      ON MATCH SET  h.type = coalesce(h.type, $head_type)\n",
    "    MERGE (t:Entity {name: $tail_name})\n",
    "      ON CREATE SET t.type = $tail_type\n",
    "      ON MATCH SET  t.type = coalesce(t.type, $tail_type)\n",
    "    MERGE (h)-[r:RELATION {name: $rel}]->(t)\n",
    "      ON CREATE SET r.evidence = $evidence,\n",
    "                    r.source = $source,\n",
    "                    r.published_at = $published_at\n",
    "    \"\"\"\n",
    "    \n",
    "    graph.run(\n",
    "        cypher,\n",
    "        head_name=head_name,\n",
    "        tail_name=tail_name,\n",
    "        rel=rel,\n",
    "        head_type=head_type,\n",
    "        tail_type=tail_type,\n",
    "        evidence=evidence,\n",
    "        source=source,\n",
    "        published_at=published_at,\n",
    "    )\n",
    "\n",
    "for _, r in triples_df.iterrows():\n",
    "    upsert_triplet_to_neo4j(r)\n",
    "\n",
    "print(\"Inserted into Neo4j!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b30f327",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Cypher:\n",
      " MATCH (amazon:Entity {name: \"Amazon\", type: \"Company\"})-[r:RELATION]->(company:Entity)\n",
      "WHERE r.name IN [\"acquired\", \"invested in\"] AND company.type = \"Company\"\n",
      "RETURN company.name, r.name, r.evidence, r.source, r.published_at\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 9 – Natural Language to Cypher query\n",
    "\n",
    "NL2CYPHER_SYSTEM = \"\"\"\n",
    "You are an assistant that converts natural language questions\n",
    "about a financial knowledge graph into Cypher queries for Neo4j.\n",
    "\n",
    "The graph schema:\n",
    "- Nodes: (:Entity {name, type})\n",
    "- Relationships: (:Entity)-[r:RELATION {name, evidence, source, published_at}]->(:Entity)\n",
    "\n",
    "Return only the Cypher query as plain text.\n",
    "\"\"\"\n",
    "\n",
    "def nl_to_cypher(question: str) -> str:\n",
    "    user_prompt = f\"\"\"\n",
    "User question:\n",
    "\\\"\\\"\\\"{question}\\\"\\\"\\\"\n",
    "\n",
    "Convert this to a Cypher query for Neo4j. Only output the Cypher query.\n",
    "\"\"\"\n",
    "    resp = client.responses.create(\n",
    "        model=\"gpt-4.1-mini\",\n",
    "        input=[\n",
    "            {\"role\": \"system\", \"content\": NL2CYPHER_SYSTEM},\n",
    "            {\"role\": \"user\", \"content\": user_prompt},\n",
    "        ],\n",
    "    )\n",
    "    cypher = resp.output[0].content[0].text.strip()\n",
    "    return cypher\n",
    "\n",
    "def ask_graph(question: str):\n",
    "    cypher = nl_to_cypher(question)\n",
    "    print(\"Generated Cypher:\\n\", cypher)\n",
    "    try:\n",
    "        result = graph.run(cypher)\n",
    "        return result.to_data_frame()\n",
    "    except Exception as e:\n",
    "        print(\"Error running Cypher:\", e)\n",
    "        return None\n",
    "\n",
    "# Example:\n",
    "df_result = ask_graph(\"Show all companies that Amazon has acquired or invested in.\")\n",
    "df_result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
